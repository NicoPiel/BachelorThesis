{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "840f1a55-6e23-4e19-b78e-732c782ef318",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_22734/30687496.py:53: DeprecationWarning: `set_matplotlib_formats` is deprecated since IPython 7.23, directly use `matplotlib_inline.backend_inline.set_matplotlib_formats()`\n",
      "  set_matplotlib_formats(\"svg\", \"pdf\")  # For export\n",
      "Global seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA: True\n",
      "Device: cuda:0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Imports\n",
    "\n",
    "import os\n",
    "import re\n",
    "from argparse import ArgumentParser\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# PyTorch Lightning\n",
    "import pytorch_lightning as pl\n",
    "import seaborn as sns\n",
    "\n",
    "# PyTorch\n",
    "import torch\n",
    "from torch import Tensor, nn, optim\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as data\n",
    "\n",
    "import torchmetrics.functional as metrics\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from IPython.display import set_matplotlib_formats\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from pytorch_lightning.tuner.tuning import Tuner\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "from pytorch_lightning.loggers import WandbLogger, NeptuneLogger\n",
    "from pytorch_tabular import TabularModel\n",
    "from pytorch_tabular.models import CategoryEmbeddingModelConfig\n",
    "from pytorch_tabular.config import DataConfig, OptimizerConfig, TrainerConfig, ExperimentConfig\n",
    "\n",
    "\n",
    "import wandb\n",
    "\n",
    "DEVICE = torch.device(\"cpu\")\n",
    "\n",
    "# Import GPU-related things\n",
    "if torch.cuda.is_available():\n",
    "    # import cupy as np\n",
    "    # import cudf as pd\n",
    "\n",
    "    # Ensure that all operations are deterministic on GPU (if used) for reproducibility\n",
    "    torch.backends.cudnn.determinstic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "    DEVICE = torch.device(\"cuda:0\")\n",
    "# else:\n",
    "\n",
    "# Plotting\n",
    "plt.set_cmap(\"cividis\")\n",
    "#%matplotlib inline\n",
    "set_matplotlib_formats(\"svg\", \"pdf\")  # For export\n",
    "matplotlib.rcParams[\"lines.linewidth\"] = 2.0\n",
    "sns.reset_orig()\n",
    "\n",
    "# Path to the folder where the datasets are/should be downloaded (e.g. CIFAR10)\n",
    "DATASET_PATH = os.environ.get(\"PATH_DATASETS\", \"data/\")\n",
    "# Path to the folder where the pretrained models are saved\n",
    "CHECKPOINT_PATH = os.environ.get(\"PATH_CHECKPOINT\", \"saved_models/\")\n",
    "\n",
    "# Setting the seed\n",
    "pl.seed_everything(42)\n",
    "\n",
    "print('CUDA:', torch.cuda.is_available())\n",
    "print(\"Device:\", DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "89c31f7a-106a-4ba0-ac38-1052c47a61cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def in_ipython():\n",
    "    try:\n",
    "        return __IPYTHON__\n",
    "    except NameError:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4e6174fc-100e-4977-87a5-58176a50bc43",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fa6ad600-86b7-4fc9-834b-677098904e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=['type', 'name'])\n",
    "y = df['type']\n",
    "\n",
    "X_encoder = preprocessing.LabelBinarizer()\n",
    "y_encoder = preprocessing.LabelBinarizer()\n",
    "\n",
    "name_trans = X_encoder.fit_transform(df['name'].to_numpy().reshape(-1, 1))\n",
    "X = pd.concat([X, pd.DataFrame(name_trans)], axis=1)\n",
    "y = y_encoder.fit_transform(y.to_numpy().reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f6fc1518-dd6d-4e36-9741-831354265a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into train+val and test\n",
    "X_trainval, X_test, y_trainval, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "# Split train into train-val\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_trainval, y_trainval, test_size=0.1, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "359828a0-b31c-4445-9cce-e5fa89b36e99",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/npiel2s/miniconda3/envs/mm/lib/python3.9/site-packages/sklearn/utils/validation.py:1858: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n",
      "/home/npiel2s/miniconda3/envs/mm/lib/python3.9/site-packages/sklearn/utils/validation.py:1858: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n",
      "/home/npiel2s/miniconda3/envs/mm/lib/python3.9/site-packages/sklearn/utils/validation.py:1858: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "scaler = preprocessing.Normalizer()\n",
    "X_train = scaler.transform(X_train)\n",
    "X_val = scaler.transform(X_val)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "X_train, y_train = np.array(X_train), np.array(y_train)\n",
    "X_val, y_val = np.array(X_val), np.array(y_val)\n",
    "X_test, y_test = np.array(X_test), np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "11a632cd-df69-435b-8323-73165083753d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class CustomDataset(data.Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        super().__init__()\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c5051912-4965-4798-b463-4f083d131eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_subfeatures(num_features, divider):\n",
    "    return int(np.floor(num_features / divider))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f7d073d5-56d0-4391-b9ce-6f4e00461e7d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class FFNetwork(pl.LightningModule):\n",
    "    def __init__(self, num_features, num_classes, dropout: float = 0.1):\n",
    "        super().__init__()\n",
    "\n",
    "        self.num_features = num_features\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "        self.sequential = nn.Sequential(\n",
    "            nn.Linear(num_features, num_features),\n",
    "            nn.Linear(num_features, num_features),\n",
    "            nn.Linear(num_features, num_features),\n",
    "            nn.Linear(num_features, num_features),\n",
    "            nn.Dropout(p=dropout),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(num_features, num_features),\n",
    "            nn.Linear(num_features, num_features),\n",
    "            nn.Linear(num_features, num_features),\n",
    "            nn.Linear(num_features, num_features),\n",
    "            nn.Dropout(p=dropout),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(num_features, num_features),\n",
    "            nn.Linear(num_features, num_features),\n",
    "            nn.Linear(num_features, num_features),\n",
    "            nn.Linear(num_features, num_features),\n",
    "            nn.Dropout(p=dropout),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(num_features, num_features),\n",
    "            nn.Linear(num_features, num_features),\n",
    "            nn.Linear(num_features, num_features),\n",
    "            nn.Linear(num_features, num_features),\n",
    "            nn.Dropout(p=dropout),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(num_features, num_features),\n",
    "            nn.Linear(num_features, num_features),\n",
    "            nn.Linear(num_features, num_features),\n",
    "            nn.Linear(num_features, num_features),\n",
    "            nn.Dropout(p=dropout),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(num_features, num_features),\n",
    "            nn.Linear(num_features, num_features),\n",
    "            nn.Linear(num_features, num_features),\n",
    "            nn.Linear(num_features, num_features),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(num_features, num_classes),\n",
    "            # nn.Softmax(dim=1)\n",
    "        )\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        loss = self._calculate_loss(batch, mode=\"train\")\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        _ = self._calculate_loss(batch, mode=\"val\")\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        _ = self._calculate_loss(batch, mode=\"test\")\n",
    "\n",
    "    def forward(self, X):\n",
    "        return self.sequential(X)\n",
    "\n",
    "    def _calculate_loss(self, batch, mode=\"train\"):\n",
    "        X, y = batch\n",
    "\n",
    "        preds = self.forward(X)\n",
    "        loss = F.cross_entropy(preds, y)\n",
    "\n",
    "        # Logging to WANDB\n",
    "        self.log(f\"{mode}_loss\", loss)\n",
    "        self.log(f'{mode}_acc', metrics.accuracy(preds, y.long(), average='macro', num_classes=self.num_classes), prog_bar=True)\n",
    "        self.log(f'{mode}_f1', metrics.f1_score(preds, y.long(), average='macro', num_classes=self.num_classes), prog_bar=True)\n",
    "        self.log(f'{mode}_prc', metrics.precision(preds, y.long(), average='macro', num_classes=self.num_classes), prog_bar=False)\n",
    "        self.log(f'{mode}_rcl', metrics.recall(preds, y.long(), average='macro', num_classes=self.num_classes), prog_bar=False)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return optim.Adam(\n",
    "            self.parameters(),\n",
    "            lr=0.001,\n",
    "            weight_decay=0.03\n",
    "        )\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return data.DataLoader(\n",
    "            CustomDataset(torch.from_numpy(X_train).float(), torch.from_numpy(y_train).float()),\n",
    "            batch_size=64,\n",
    "            shuffle=True,\n",
    "            num_workers=8\n",
    "        )\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return data.DataLoader(\n",
    "            CustomDataset(torch.from_numpy(X_val).float(), torch.from_numpy(y_val).float()),\n",
    "            batch_size=1,\n",
    "            num_workers=8\n",
    "        )\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return data.DataLoader(\n",
    "            CustomDataset(torch.from_numpy(X_test).float(), torch.from_numpy(y_test).float()),\n",
    "            batch_size=1,\n",
    "            num_workers=8\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2411315f-2495-4972-a0cd-31b9f8da6a5d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# train.py\n",
    "def main(hparams):\n",
    "    # wandb.finish()\n",
    "    # wandb_logger = WandbLogger(project=\"bachelor\")\n",
    "\n",
    "    neptune_logger = NeptuneLogger(\n",
    "        project=\"caigh/bachelor\",\n",
    "        api_key=\"eyJhcGlfYWRkcmVzcyI6Imh0dHBzOi8vYXBwLm5lcHR1bmUuYWkiLCJhcGlfdXJsIjoiaHR0cHM6Ly9hcHAubmVwdHVuZS5haSIsImFwaV9rZXkiOiI4NjQyYTAwMy1jMmJkLTRjMzctYWQ0Zi03Y2FmYjQ1YmQ2Y2MifQ==\",\n",
    "        log_model_checkpoints=True,\n",
    "    )\n",
    "\n",
    "    neptune_logger.finalize('success')\n",
    "\n",
    "    print('Loading data..')\n",
    "    print(f'X shape: {X.shape[1]}')\n",
    "    print(f'y shape: {y.shape[1]}')\n",
    "\n",
    "    model = FFNetwork(\n",
    "        num_features=X.shape[1],\n",
    "        num_classes=y.shape[1],\n",
    "        dropout=0.5\n",
    "    )\n",
    "\n",
    "    # train the model\n",
    "    trainer = pl.Trainer(\n",
    "        accelerator='gpu',\n",
    "        strategy='dp',\n",
    "        precision=16,\n",
    "        max_epochs=10,\n",
    "        min_epochs=1,\n",
    "        # overfit_batches=1,\n",
    "        logger=neptune_logger,\n",
    "        callbacks=[\n",
    "            EarlyStopping(monitor=\"train_loss\", mode=\"min\"),\n",
    "            ModelCheckpoint(dirpath='./checkpoints', filename='{epoch}-{val_loss:.2f}-{val_f1:.2f}', monitor='val_f1', save_last=True),\n",
    "        ],\n",
    "     )\n",
    "\n",
    "    trainer.fit(model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "165cf464-e658-4d44-b207-7b5bc7a2526c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "You want to use the `Neptune` logger which is not installed yet, install it with `pip install neptune-client`.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [11], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m     main(hyperparams)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 10\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn [10], line 6\u001b[0m, in \u001b[0;36mmain\u001b[0;34m(hparams)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmain\u001b[39m(hparams):\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;66;03m# wandb.finish()\u001b[39;00m\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;66;03m# wandb_logger = WandbLogger(project=\"bachelor\")\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m     neptune_logger \u001b[38;5;241m=\u001b[39m \u001b[43mNeptuneLogger\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproject\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcaigh/bachelor\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m        \u001b[49m\u001b[43mapi_key\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43meyJhcGlfYWRkcmVzcyI6Imh0dHBzOi8vYXBwLm5lcHR1bmUuYWkiLCJhcGlfdXJsIjoiaHR0cHM6Ly9hcHAubmVwdHVuZS5haSIsImFwaV9rZXkiOiI4NjQyYTAwMy1jMmJkLTRjMzctYWQ0Zi03Y2FmYjQ1YmQ2Y2MifQ==\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlog_model_checkpoints\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m     neptune_logger\u001b[38;5;241m.\u001b[39mfinalize(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msuccess\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLoading data..\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/mm/lib/python3.9/site-packages/pytorch_lightning/loggers/neptune.py:280\u001b[0m, in \u001b[0;36mNeptuneLogger.__init__\u001b[0;34m(self, api_key, project, name, run, log_model_checkpoints, prefix, agg_key_funcs, agg_default_func, **neptune_run_kwargs)\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_verify_input_arguments(api_key, project, name, run, neptune_run_kwargs)\n\u001b[1;32m    279\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m neptune \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 280\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mModuleNotFoundError\u001b[39;00m(\n\u001b[1;32m    281\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou want to use the `Neptune` logger which is not installed yet, install it with\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    282\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m `pip install neptune-client`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    283\u001b[0m     )\n\u001b[1;32m    285\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(agg_key_funcs\u001b[38;5;241m=\u001b[39magg_key_funcs, agg_default_func\u001b[38;5;241m=\u001b[39magg_default_func)\n\u001b[1;32m    286\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_log_model_checkpoints \u001b[38;5;241m=\u001b[39m log_model_checkpoints\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: You want to use the `Neptune` logger which is not installed yet, install it with `pip install neptune-client`."
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    if not in_ipython():\n",
    "        root_dir = os.path.dirname(os.path.realpath(__file__))\n",
    "        parser = ArgumentParser(add_help=False)\n",
    "        hyperparams = parser.parse_args()\n",
    "\n",
    "        # TRAIN\n",
    "        main(hyperparams)\n",
    "    else:\n",
    "        main(None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
