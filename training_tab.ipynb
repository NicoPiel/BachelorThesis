{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "840f1a55-6e23-4e19-b78e-732c782ef318",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA: True\n",
      "Device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "\n",
    "import os\n",
    "import re\n",
    "from argparse import ArgumentParser\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "import torchmetrics.functional as metrics\n",
    "\n",
    "from pytorch_tabular import TabularModel\n",
    "from pytorch_tabular.models import CategoryEmbeddingModelConfig, TabNetModelConfig\n",
    "from pytorch_tabular.config import DataConfig, OptimizerConfig, TrainerConfig, ExperimentConfig\n",
    "from pytorch_tabular.utils import get_balanced_sampler, get_class_weighted_cross_entropy\n",
    "\n",
    "\n",
    "\n",
    "import wandb\n",
    "\n",
    "DEVICE = torch.device(\"cpu\")\n",
    "\n",
    "# Import GPU-related things\n",
    "if torch.cuda.is_available():\n",
    "    # import cupy as np\n",
    "    # import cudf as pd\n",
    "\n",
    "    # Ensure that all operations are deterministic on GPU (if used) for reproducibility\n",
    "    torch.backends.cudnn.determinstic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "    DEVICE = torch.device(\"cuda:0\")\n",
    "# else:\n",
    "\n",
    "# Path to the folder where the datasets are/should be downloaded (e.g. CIFAR10)\n",
    "DATASET_PATH = os.environ.get(\"PATH_DATASETS\", \"data/\")\n",
    "# Path to the folder where the pretrained models are saved\n",
    "CHECKPOINT_PATH = os.environ.get(\"PATH_CHECKPOINT\", \"saved_models/\")\n",
    "\n",
    "# Setting the seed\n",
    "pl.seed_everything(42)\n",
    "\n",
    "print('CUDA:', torch.cuda.is_available())\n",
    "print(\"Device:\", DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "89c31f7a-106a-4ba0-ac38-1052c47a61cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def in_ipython():\n",
    "    try:\n",
    "        return __IPYTHON__\n",
    "    except NameError:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4e6174fc-100e-4977-87a5-58176a50bc43",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5c17aef2-f40f-4f11-8c0b-0574a97f202c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Int64Index([5], dtype='int64')\n",
      "37\n",
      "37\n"
     ]
    }
   ],
   "source": [
    "drop_n9 = df.loc[df['type'] == 'n9'].index\n",
    "df = df.drop(index=drop_n9)\n",
    "\n",
    "target_col = ['type']\n",
    "\n",
    "cat_columns = [\n",
    "    'name',\n",
    "    'isA',\n",
    "    'isR'\n",
    "]\n",
    "\n",
    "target_and_cat = target_col.copy()\n",
    "target_and_cat.extend(cat_columns)\n",
    "\n",
    "cont_columns = df.drop(columns=target_and_cat).columns.values.tolist()\n",
    "\n",
    "target = df['type']\n",
    "\n",
    "train, test = train_test_split(df, random_state=42, stratify=target)\n",
    "train, val = train_test_split(train, random_state=42, stratify=train['type'])\n",
    "\n",
    "print(len(df['type'].unique()))\n",
    "print(len(train['type'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "73aa2c8d-b495-49b6-b2b2-2f88ccaacafc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_metrics(y_true, y_pred, tag):\n",
    "    if isinstance(y_true, pd.DataFrame) or isinstance(y_true, pd.Series):\n",
    "        y_true = y_true.values\n",
    "    if isinstance(y_pred, pd.DataFrame) or isinstance(y_pred, pd.Series):\n",
    "        y_pred = y_pred.values\n",
    "    if y_true.ndim>1:\n",
    "        y_true=y_true.ravel()\n",
    "    if y_pred.ndim>1:\n",
    "        y_pred=y_pred.ravel()\n",
    "    val_acc = metrics.accuracy(y_pred, y_true)\n",
    "    val_f1 = metrics.f1_score1(y_pred, y_true)\n",
    "    print(f\"{tag} Acc: {val_acc} | {tag} F1: {val_f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2411315f-2495-4972-a0cd-31b9f8da6a5d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# train.py\n",
    "def main(hparams):\n",
    "    wandb.finish()\n",
    "    sampler = get_balanced_sampler(df['type'].values.ravel())\n",
    "\n",
    "    data_config = DataConfig(\n",
    "        target=['type'], #target should always be a list. Multi-targets are only supported for regression. Multi-Task Classification is not implemented\n",
    "        continuous_cols=cont_columns,\n",
    "        categorical_cols=cat_columns\n",
    "    )\n",
    "\n",
    "    trainer_config = TrainerConfig(\n",
    "        auto_lr_find=True, # Runs the LRFinder to automatically derive a learning rate\n",
    "        batch_size=1024,\n",
    "        max_epochs=10,\n",
    "        gpus=1, #index of the GPU to use. -1 means all available GPUs, None, means CPU\n",
    "    )\n",
    "\n",
    "    optimizer_config = OptimizerConfig()\n",
    "\n",
    "    model_config = TabNetModelConfig(\n",
    "        task=\"classification\",\n",
    "    )\n",
    "\n",
    "    experiment_config = ExperimentConfig(\n",
    "        project_name='bachelor',\n",
    "        exp_watch='gradients',\n",
    "        log_target='wandb',\n",
    "        log_logits=True\n",
    "    )\n",
    "\n",
    "    tabular_model = TabularModel(\n",
    "        data_config=data_config,\n",
    "        model_config=model_config,\n",
    "        optimizer_config=optimizer_config,\n",
    "        trainer_config=trainer_config,\n",
    "        experiment_config=experiment_config\n",
    "    )\n",
    "\n",
    "    tabular_model.fit(train=train, validation=val, train_sampler=sampler)\n",
    "    result = tabular_model.evaluate(test)\n",
    "\n",
    "    print(result)\n",
    "\n",
    "    pred_df = tabular_model.predict(test)\n",
    "    pred_df.head()\n",
    "\n",
    "    print_metrics(test['type'], pred_df[\"prediction\"], tag=\"Holdout\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "165cf464-e658-4d44-b207-7b5bc7a2526c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mcaigh\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.3 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>./wandb/run-20220919_233117-2rm594y9</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/caigh/bachelor/runs/2rm594y9\" target=\"_blank\">classification_14</a></strong> to <a href=\"https://wandb.ai/caigh/bachelor\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: logging graph, to disable use `wandb.watch(log_graph=False)`\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "__init__() got an unexpected keyword argument 'checkpoint_callback'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [7], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m     main(hyperparams)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 10\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn [6], line 40\u001b[0m, in \u001b[0;36mmain\u001b[0;34m(hparams)\u001b[0m\n\u001b[1;32m     25\u001b[0m experiment_config \u001b[38;5;241m=\u001b[39m ExperimentConfig(\n\u001b[1;32m     26\u001b[0m     project_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbachelor\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     27\u001b[0m     exp_watch\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgradients\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     28\u001b[0m     log_target\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwandb\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     29\u001b[0m     log_logits\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     30\u001b[0m )\n\u001b[1;32m     32\u001b[0m tabular_model \u001b[38;5;241m=\u001b[39m TabularModel(\n\u001b[1;32m     33\u001b[0m     data_config\u001b[38;5;241m=\u001b[39mdata_config,\n\u001b[1;32m     34\u001b[0m     model_config\u001b[38;5;241m=\u001b[39mmodel_config,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     37\u001b[0m     experiment_config\u001b[38;5;241m=\u001b[39mexperiment_config\n\u001b[1;32m     38\u001b[0m )\n\u001b[0;32m---> 40\u001b[0m \u001b[43mtabular_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_sampler\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msampler\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     41\u001b[0m result \u001b[38;5;241m=\u001b[39m tabular_model\u001b[38;5;241m.\u001b[39mevaluate(test)\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28mprint\u001b[39m(result)\n",
      "File \u001b[0;32m~/miniconda3/envs/mm/lib/python3.9/site-packages/pytorch_tabular/tabular_model.py:431\u001b[0m, in \u001b[0;36mTabularModel.fit\u001b[0;34m(self, train, validation, test, loss, metrics, optimizer, optimizer_params, train_sampler, target_transform, max_epochs, min_epochs, reset, seed)\u001b[0m\n\u001b[1;32m    395\u001b[0m \u001b[38;5;124;03m\"\"\"The fit method which takes in the data and triggers the training\u001b[39;00m\n\u001b[1;32m    396\u001b[0m \n\u001b[1;32m    397\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    428\u001b[0m \u001b[38;5;124;03m    seed: (int): If you have to override the default seed set as part of of ModelConfig\u001b[39;00m\n\u001b[1;32m    429\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    430\u001b[0m seed_everything(seed \u001b[38;5;28;01mif\u001b[39;00m seed \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mseed)\n\u001b[0;32m--> 431\u001b[0m train_loader, val_loader \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_pre_fit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    432\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    433\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    434\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    435\u001b[0m \u001b[43m    \u001b[49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    436\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetrics\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    437\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    438\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimizer_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    439\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_sampler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    440\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget_transform\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    441\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_epochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    442\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmin_epochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    443\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    444\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    445\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m    446\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mauto_lr_find \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mfast_dev_run):\n",
      "File \u001b[0;32m~/miniconda3/envs/mm/lib/python3.9/site-packages/pytorch_tabular/tabular_model.py:376\u001b[0m, in \u001b[0;36mTabularModel._pre_fit\u001b[0;34m(self, train, validation, test, loss, metrics, optimizer, optimizer_params, train_sampler, target_transform, max_epochs, min_epochs, reset)\u001b[0m\n\u001b[1;32m    372\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlogger\u001b[38;5;241m.\u001b[39mwatch(\n\u001b[1;32m    373\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel, log\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mexp_watch, log_freq\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mexp_log_freq\n\u001b[1;32m    374\u001b[0m     )\n\u001b[1;32m    375\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallbacks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_callbacks()\n\u001b[0;32m--> 376\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_prepare_trainer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmax_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmin_epochs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    377\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m train_loader, val_loader\n",
      "File \u001b[0;32m~/miniconda3/envs/mm/lib/python3.9/site-packages/pytorch_tabular/tabular_model.py:310\u001b[0m, in \u001b[0;36mTabularModel._prepare_trainer\u001b[0;34m(self, max_epochs, min_epochs)\u001b[0m\n\u001b[1;32m    308\u001b[0m \u001b[38;5;66;03m# For some weird reason, checkpoint_callback is not appearing in the Trainer vars\u001b[39;00m\n\u001b[1;32m    309\u001b[0m trainer_args_config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcheckpoint_callback\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mcheckpoint_callback\n\u001b[0;32m--> 310\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer \u001b[38;5;241m=\u001b[39m \u001b[43mpl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTrainer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    311\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlogger\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlogger\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    312\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    313\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mtrainer_args_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    314\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/mm/lib/python3.9/site-packages/pytorch_lightning/utilities/argparse.py:345\u001b[0m, in \u001b[0;36m_defaults_from_env_vars.<locals>.insert_env_defaults\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    342\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(\u001b[38;5;28mlist\u001b[39m(env_variables\u001b[38;5;241m.\u001b[39mitems()) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mlist\u001b[39m(kwargs\u001b[38;5;241m.\u001b[39mitems()))\n\u001b[1;32m    344\u001b[0m \u001b[38;5;66;03m# all args were already moved to kwargs\u001b[39;00m\n\u001b[0;32m--> 345\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'checkpoint_callback'"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    if not in_ipython():\n",
    "        root_dir = os.path.dirname(os.path.realpath(__file__))\n",
    "        parser = ArgumentParser(add_help=False)\n",
    "        hyperparams = parser.parse_args()\n",
    "\n",
    "        # TRAIN\n",
    "        main(hyperparams)\n",
    "    else:\n",
    "        main(None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
