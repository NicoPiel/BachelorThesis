{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "840f1a55-6e23-4e19-b78e-732c782ef318",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA: True\n",
      "Device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "\n",
    "import os\n",
    "import re\n",
    "from argparse import ArgumentParser\n",
    "from glob import glob\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "import torch_geometric as pyg\n",
    "import torch_geometric.nn as pygnn\n",
    "import torchmetrics.functional as metrics\n",
    "from torchmetrics import Accuracy, F1Score\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "import pytorch_lightning.callbacks as callbacks\n",
    "\n",
    "import dgl\n",
    "\n",
    "DEVICE = torch.device(\"cpu\")\n",
    "\n",
    "# Import GPU-related things\n",
    "if torch.cuda.is_available():\n",
    "    # import cupy as np\n",
    "    # import cudf as pd\n",
    "\n",
    "    # Ensure that all operations are deterministic on GPU (if used) for reproducibility\n",
    "    torch.backends.cudnn.determinstic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "    DEVICE = torch.device(\"cuda:0\")\n",
    "# else:\n",
    "\n",
    "# Path to the folder where the datasets are/should be downloaded (e.g. CIFAR10)\n",
    "DATASET_PATH = os.environ.get(\"PATH_DATASETS\", \"data/\")\n",
    "# Path to the folder where the pretrained models are saved\n",
    "CHECKPOINT_PATH = os.environ.get(\"PATH_CHECKPOINT\", \"saved_models/\")\n",
    "\n",
    "print('CUDA:', torch.cuda.is_available())\n",
    "print(\"Device:\", DEVICE)\n",
    "\n",
    "temp_path = './temp'\n",
    "data_path = './data'\n",
    "\n",
    "if not os.path.exists(temp_path):\n",
    "    os.mkdir(temp_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "89c31f7a-106a-4ba0-ac38-1052c47a61cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def in_ipython():\n",
    "    try:\n",
    "        return __IPYTHON__\n",
    "    except NameError:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cddf1831-515b-457b-a450-04fe9efb6ebc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done loading data from cached files.\n"
     ]
    }
   ],
   "source": [
    "dataset_dgl = dgl.data.CSVDataset('./graph_data')\n",
    "dgl.data.utils.add_nodepred_split(dataset_dgl, [0.8, 0.1, 0.1])\n",
    "dataset_batched = dgl.batch(dataset_dgl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bfa525d3-7078-4f29-b2e1-b42b0100f57f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<networkx.classes.multidigraph.MultiDiGraph at 0x7fde4d1b1cf0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_nx = dgl.to_networkx(\n",
    "    dataset_batched,\n",
    "    node_attrs=[\n",
    "        'label',\n",
    "        'type',\n",
    "        'depDeg',\n",
    "        'forC',\n",
    "        'isA',\n",
    "        'totDeg',\n",
    "        'totH',\n",
    "        'totV',\n",
    "        'isR',\n",
    "        'train_mask',\n",
    "        'test_mask',\n",
    "        'val_mask'\n",
    "    ],\n",
    "    edge_attrs=[\n",
    "        'label',\n",
    "        'bond_type'\n",
    "    ]\n",
    ")\n",
    "\n",
    "dataset_nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "593b7139-b43b-4cb6-80ef-2deb455706d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(edge_index=[2, 2489088], id=[2489088], x=[2407753, 13], edge_attr=[2489088, 2])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pyg.utils.from_networkx(\n",
    "    dataset_nx,\n",
    "    group_node_attrs=[\n",
    "        'label',\n",
    "        'type',\n",
    "        'depDeg',\n",
    "        'forC',\n",
    "        'isA',\n",
    "        'totDeg',\n",
    "        'totH',\n",
    "        'totV',\n",
    "        'isR',\n",
    "        'train_mask',\n",
    "        'test_mask',\n",
    "        'val_mask'\n",
    "    ],\n",
    "    group_edge_attrs=[\n",
    "        'label',\n",
    "        'bond_type'\n",
    "    ]\n",
    ")\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c418abdc-379e-40e4-bf3f-c8dd1f1ef2e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataset(input_dataset):\n",
    "    dataset_out = input_dataset\n",
    "\n",
    "    dataset_features = torch.column_stack(\n",
    "        [input_dataset.x[:, 0], input_dataset.x[:, 2:-3]]\n",
    "    )\n",
    "    dataset_target = input_dataset.x[:, 1]\n",
    "\n",
    "    dataset_out.x = dataset_features.float()\n",
    "    dataset_out.y = dataset_target.long()\n",
    "    dataset_out.train_mask = input_dataset.x[:, -3].bool()\n",
    "    dataset_out.test_mask = input_dataset.x[:, -2].bool()\n",
    "    dataset_out.val_mask = input_dataset.x[:, -1].bool()\n",
    "    dataset_out.num_node_features = dataset_out.x.size(1)\n",
    "    dataset_out.num_classes = torch.unique(dataset_out.y).size(0)\n",
    "\n",
    "    print(dataset_out.num_classes)\n",
    "\n",
    "    return dataset_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "04e6f642-847e-4407-82ac-d15d546166cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38\n"
     ]
    }
   ],
   "source": [
    "dataset_t = prepare_dataset(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b7ec3ff7-34f3-4c94-adef-18d25b7d83d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MolNet(pl.LightningModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels: int,\n",
    "        out_channels: int,\n",
    "        hidden_channels: int = 256,\n",
    "        num_layers: int = 2,\n",
    "        dropout: float = 0.0\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.gnn = pygnn.GraphSAGE(\n",
    "            in_channels,\n",
    "            hidden_channels,\n",
    "            num_layers,\n",
    "            out_channels,\n",
    "            dropout=dropout,\n",
    "            norm=nn.BatchNorm1d(hidden_channels)\n",
    "        )\n",
    "\n",
    "        self.train_acc = Accuracy()\n",
    "        self.train_f1 = F1Score()\n",
    "\n",
    "        self.val_acc = Accuracy()\n",
    "        self.val_f1 = F1Score()\n",
    "\n",
    "        self.test_acc = Accuracy()\n",
    "        self.test_f1 = F1Score()\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        return self.gnn(x, edge_index)\n",
    "\n",
    "    def training_step(self, graph, batch_idx):\n",
    "        y_hat = self(graph.x[graph.train_mask], graph.edge_index)\n",
    "        y = graph.y[graph.train_mask]\n",
    "        loss = F.cross_entropy(y_hat, y)\n",
    "\n",
    "        self.train_acc(y_hat.softmax(dim=-1), y)\n",
    "        self.train_f1(y_hat.softmax(dim=-1), y)\n",
    "\n",
    "        self.log(\n",
    "            'train_acc',\n",
    "            self.train_acc,\n",
    "            prog_bar=True,\n",
    "            on_step=False,\n",
    "            on_epoch=True\n",
    "        )\n",
    "\n",
    "        self.log(\n",
    "            'train_f1',\n",
    "            self.train_f1,\n",
    "            prog_bar=True,\n",
    "            on_step=False,\n",
    "            on_epoch=True\n",
    "        )\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, graph, batch_idx):\n",
    "        y_hat = self(graph.x[graph.val_mask], graph.edge_index)\n",
    "        y = graph.y[graph.val_mask]\n",
    "\n",
    "        self.val_acc(y_hat.softmax(dim=-1), y)\n",
    "        self.val_f1(y_hat.softmax(dim=-1), y)\n",
    "\n",
    "        self.log(\n",
    "            'val_acc',\n",
    "            self.val_acc,\n",
    "            prog_bar=True,\n",
    "            on_step=False,\n",
    "            on_epoch=True\n",
    "        )\n",
    "\n",
    "        self.log(\n",
    "            'val_f1',\n",
    "            self.val_f1,\n",
    "            prog_bar=True,\n",
    "            on_step=False,\n",
    "            on_epoch=True\n",
    "        )\n",
    "\n",
    "    def test_step(self, graph, batch_idx):\n",
    "        y_hat = self(data.x[graph.test_mask], data.edge_index)\n",
    "        y = graph.y[graph.test_mask]\n",
    "\n",
    "        self.test_acc(y_hat.softmax(dim=-1), y)\n",
    "        self.test_f1(y_hat.softmax(dim=-1), y)\n",
    "\n",
    "        self.log(\n",
    "            'test_acc',\n",
    "            self.test_acc,\n",
    "            prog_bar=True,\n",
    "            on_step=False,\n",
    "            on_epoch=True\n",
    "        )\n",
    "\n",
    "        self.log(\n",
    "            'test_f1',\n",
    "            self.test_f1,\n",
    "            prog_bar=True,\n",
    "            on_step=False,\n",
    "            on_epoch=True\n",
    "        )\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "11fefb75-5647-420f-86de-9c82171de8de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(hparams):\n",
    "    #     optimizer = torch.optim.Adamax(model.parameters(), lr=1e-6, weight_decay=5e-4)\n",
    "\n",
    "    #     model.train()\n",
    "    #     for epoch in range(750):\n",
    "    #         optimizer.zero_grad()\n",
    "    #         out = model(dataset_gpu.x, dataset_gpu.edge_index)\n",
    "    #         loss = F.cross_entropy(out[dataset_gpu.train_mask], dataset_gpu.y[dataset_gpu.train_mask])\n",
    "    #         loss.backward()\n",
    "    #         optimizer.step()\n",
    "\n",
    "    #         train_f1 = metrics.f1_score(\n",
    "    #             out[dataset_gpu.test_mask],\n",
    "    #             dataset_gpu.y[dataset_gpu.test_mask],\n",
    "    #             average='weighted',\n",
    "    #             num_classes=dataset_gpu.num_classes\n",
    "    #         )\n",
    "    #         print(loss)\n",
    "    #         print(f'Epoch {epoch}: loss={loss}, f1={train_f1}')\n",
    "\n",
    "    #     model.eval()\n",
    "    #     pred = model(dataset_gpu.x, dataset_gpu.edge_index).argmax(dim=1)\n",
    "\n",
    "    #     acc = metrics.accuracy(\n",
    "    #         pred[dataset_gpu.test_mask],\n",
    "    #         dataset_gpu.y[dataset_gpu.test_mask],\n",
    "    #         average='weighted',\n",
    "    #         num_classes=dataset_gpu.num_classes\n",
    "    #     )\n",
    "\n",
    "    #     f1 = metrics.f1_score(\n",
    "    #         pred[dataset_gpu.test_mask],\n",
    "    #         dataset_gpu.y[dataset_gpu.test_mask],\n",
    "    #         average='weighted',\n",
    "    #         num_classes=dataset_gpu.num_classes\n",
    "    #     )\n",
    "\n",
    "    #     print(f'Accuracy: {acc:.4f}')\n",
    "    #     print(f'F1: {f1:.4f}')\n",
    "\n",
    "    datamodule = pyg.data.LightningNodeData(\n",
    "        dataset_t,\n",
    "        dataset_t.train_mask,\n",
    "        dataset_t.val_mask,\n",
    "        dataset_t.test_mask,\n",
    "        loader='neighbor',\n",
    "        batch_size=1,\n",
    "        num_neighbors=[25, 10],\n",
    "    )\n",
    "\n",
    "    model = MolNet(dataset_t.num_node_features, dataset_t.num_classes)\n",
    "\n",
    "    # devices = torch.cuda.device_count()\n",
    "    strategy = pl.strategies.SingleDeviceStrategy(device=DEVICE)\n",
    "    checkpoint = pl.callbacks.ModelCheckpoint(monitor='val_acc', save_top_k=1)\n",
    "\n",
    "    trainer = pl.Trainer(\n",
    "        strategy=strategy,\n",
    "        accelerator='gpu',\n",
    "        devices=1,\n",
    "        max_epochs=20,\n",
    "        callbacks=[checkpoint],\n",
    "        fast_dev_run=True,\n",
    "        precision=16\n",
    "    )\n",
    "\n",
    "    trainer.fit(model, datamodule)\n",
    "    trainer.test(ckpt_path='best', datamodule=datamodule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "165cf464-e658-4d44-b207-7b5bc7a2526c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit native Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Running in `fast_dev_run` mode: will run the requested loop using 1 batch(es). Logging and checkpointing is suppressed.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name      | Type      | Params\n",
      "----------------------------------------\n",
      "0 | gnn       | GraphSAGE | 24.9 K\n",
      "1 | train_acc | Accuracy  | 0     \n",
      "2 | val_acc   | Accuracy  | 0     \n",
      "3 | test_acc  | Accuracy  | 0     \n",
      "----------------------------------------\n",
      "24.9 K    Trainable params\n",
      "0         Non-trainable params\n",
      "24.9 K    Total params\n",
      "0.050     Total estimated model params size (MB)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "num_samples should be a positive integer value, but got num_samples=0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [10], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m     main(hyperparams)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 10\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn [9], line 67\u001b[0m, in \u001b[0;36mmain\u001b[0;34m(hparams)\u001b[0m\n\u001b[1;32m     55\u001b[0m checkpoint \u001b[38;5;241m=\u001b[39m pl\u001b[38;5;241m.\u001b[39mcallbacks\u001b[38;5;241m.\u001b[39mModelCheckpoint(monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_acc\u001b[39m\u001b[38;5;124m'\u001b[39m, save_top_k\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     57\u001b[0m trainer \u001b[38;5;241m=\u001b[39m pl\u001b[38;5;241m.\u001b[39mTrainer(\n\u001b[1;32m     58\u001b[0m     strategy\u001b[38;5;241m=\u001b[39mstrategy,\n\u001b[1;32m     59\u001b[0m     accelerator\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgpu\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     64\u001b[0m     precision\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m16\u001b[39m\n\u001b[1;32m     65\u001b[0m )\n\u001b[0;32m---> 67\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     68\u001b[0m trainer\u001b[38;5;241m.\u001b[39mtest(ckpt_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbest\u001b[39m\u001b[38;5;124m'\u001b[39m, datamodule\u001b[38;5;241m=\u001b[39mdatamodule)\n",
      "File \u001b[0;32m~/miniconda3/envs/mmpyg/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:696\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    677\u001b[0m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    678\u001b[0m \u001b[38;5;124;03mRuns the full optimization routine.\u001b[39;00m\n\u001b[1;32m    679\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    693\u001b[0m \u001b[38;5;124;03m    datamodule: An instance of :class:`~pytorch_lightning.core.datamodule.LightningDataModule`.\u001b[39;00m\n\u001b[1;32m    694\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    695\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m model\n\u001b[0;32m--> 696\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_and_handle_interrupt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    697\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_impl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\n\u001b[1;32m    698\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/mmpyg/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:650\u001b[0m, in \u001b[0;36mTrainer._call_and_handle_interrupt\u001b[0;34m(self, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    648\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mlauncher\u001b[38;5;241m.\u001b[39mlaunch(trainer_fn, \u001b[38;5;241m*\u001b[39margs, trainer\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    649\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 650\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrainer_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    651\u001b[0m \u001b[38;5;66;03m# TODO(awaelchli): Unify both exceptions below, where `KeyboardError` doesn't re-raise\u001b[39;00m\n\u001b[1;32m    652\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exception:\n",
      "File \u001b[0;32m~/miniconda3/envs/mmpyg/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:735\u001b[0m, in \u001b[0;36mTrainer._fit_impl\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    731\u001b[0m ckpt_path \u001b[38;5;241m=\u001b[39m ckpt_path \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresume_from_checkpoint\n\u001b[1;32m    732\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ckpt_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__set_ckpt_path(\n\u001b[1;32m    733\u001b[0m     ckpt_path, model_provided\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, model_connected\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    734\u001b[0m )\n\u001b[0;32m--> 735\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mckpt_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    737\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mstopped\n\u001b[1;32m    738\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/mmpyg/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:1166\u001b[0m, in \u001b[0;36mTrainer._run\u001b[0;34m(self, model, ckpt_path)\u001b[0m\n\u001b[1;32m   1162\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_checkpoint_connector\u001b[38;5;241m.\u001b[39mrestore_training_state()\n\u001b[1;32m   1164\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_checkpoint_connector\u001b[38;5;241m.\u001b[39mresume_end()\n\u001b[0;32m-> 1166\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_stage\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1168\u001b[0m log\u001b[38;5;241m.\u001b[39mdetail(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: trainer tearing down\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1169\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_teardown()\n",
      "File \u001b[0;32m~/miniconda3/envs/mmpyg/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:1252\u001b[0m, in \u001b[0;36mTrainer._run_stage\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1250\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredicting:\n\u001b[1;32m   1251\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_predict()\n\u001b[0;32m-> 1252\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/mmpyg/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:1283\u001b[0m, in \u001b[0;36mTrainer._run_train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1280\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit_loop\u001b[38;5;241m.\u001b[39mtrainer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\n\u001b[1;32m   1282\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mset_detect_anomaly(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_detect_anomaly):\n\u001b[0;32m-> 1283\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_loop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/mmpyg/lib/python3.10/site-packages/pytorch_lightning/loops/loop.py:195\u001b[0m, in \u001b[0;36mLoop.run\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    191\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_skip()\n\u001b[1;32m    193\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreset()\n\u001b[0;32m--> 195\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mon_run_start\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    197\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdone:\n\u001b[1;32m    198\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/mmpyg/lib/python3.10/site-packages/pytorch_lightning/loops/fit_loop.py:211\u001b[0m, in \u001b[0;36mFitLoop.on_run_start\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    208\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iteration_based_training():\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mepoch_progress\u001b[38;5;241m.\u001b[39mcurrent\u001b[38;5;241m.\u001b[39mcompleted \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mepoch_progress\u001b[38;5;241m.\u001b[39mcurrent\u001b[38;5;241m.\u001b[39mprocessed\n\u001b[0;32m--> 211\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreset_train_dataloader\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlightning_module\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    212\u001b[0m \u001b[38;5;66;03m# reload the evaluation dataloaders too for proper display in the progress bar\u001b[39;00m\n\u001b[1;32m    213\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mepoch_loop\u001b[38;5;241m.\u001b[39m_should_check_val_epoch():\n",
      "File \u001b[0;32m~/miniconda3/envs/mmpyg/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:1812\u001b[0m, in \u001b[0;36mTrainer.reset_train_dataloader\u001b[0;34m(self, model)\u001b[0m\n\u001b[1;32m   1809\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (source\u001b[38;5;241m.\u001b[39mis_defined() \u001b[38;5;129;01mand\u001b[39;00m has_step \u001b[38;5;129;01mand\u001b[39;00m enable_training):\n\u001b[1;32m   1810\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m-> 1812\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_dataloader \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data_connector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request_dataloader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mRunningStage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTRAINING\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1814\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moverfit_batches \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1815\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_dataloader \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data_connector\u001b[38;5;241m.\u001b[39m_resolve_overfit_batches(\n\u001b[1;32m   1816\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_dataloader, mode\u001b[38;5;241m=\u001b[39mRunningStage\u001b[38;5;241m.\u001b[39mTRAINING\n\u001b[1;32m   1817\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/mmpyg/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:453\u001b[0m, in \u001b[0;36mDataConnector._request_dataloader\u001b[0;34m(self, stage)\u001b[0m\n\u001b[1;32m    446\u001b[0m source \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstage\u001b[38;5;241m.\u001b[39mdataloader_prefix\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_dataloader_source\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    448\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _replace_dunder_methods(DataLoader, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdataset\u001b[39m\u001b[38;5;124m\"\u001b[39m), _replace_dunder_methods(BatchSampler):\n\u001b[1;32m    449\u001b[0m     \u001b[38;5;66;03m# under this context manager, the arguments passed to `DataLoader.__init__` will be captured and saved as\u001b[39;00m\n\u001b[1;32m    450\u001b[0m     \u001b[38;5;66;03m# attributes on the instance in case the dataloader needs to be re-instantiated later by Lightning.\u001b[39;00m\n\u001b[1;32m    451\u001b[0m     \u001b[38;5;66;03m# Also, it records all attribute setting and deletion using patched `__setattr__` and `__delattr__`\u001b[39;00m\n\u001b[1;32m    452\u001b[0m     \u001b[38;5;66;03m# methods so that the re-instantiated object is as close to the original as possible.\u001b[39;00m\n\u001b[0;32m--> 453\u001b[0m     dataloader \u001b[38;5;241m=\u001b[39m \u001b[43msource\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataloader\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    454\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(dataloader, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m    455\u001b[0m     dataloader \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(dataloader)\n",
      "File \u001b[0;32m~/miniconda3/envs/mmpyg/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:530\u001b[0m, in \u001b[0;36m_DataLoaderSource.dataloader\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    528\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minstance, LightningDataModule):\n\u001b[1;32m    529\u001b[0m     method \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minstance, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname)\n\u001b[0;32m--> 530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    532\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minstance\n",
      "File \u001b[0;32m~/miniconda3/envs/mmpyg/lib/python3.10/site-packages/torch_geometric/data/lightning_datamodule.py:350\u001b[0m, in \u001b[0;36mLightningNodeData.train_dataloader\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    348\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain_dataloader\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataLoader:\n\u001b[1;32m    349\u001b[0m     \u001b[38;5;124;03m\"\"\"\"\"\"\u001b[39;00m\n\u001b[0;32m--> 350\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataloader\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput_train_nodes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/mmpyg/lib/python3.10/site-packages/torch_geometric/data/lightning_datamodule.py:342\u001b[0m, in \u001b[0;36mLightningNodeData.dataloader\u001b[0;34m(self, input_nodes, shuffle)\u001b[0m\n\u001b[1;32m    337\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mDataLoader([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata], shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    338\u001b[0m                                        collate_fn\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m xs: xs[\u001b[38;5;241m0\u001b[39m],\n\u001b[1;32m    339\u001b[0m                                        \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwargs)\n\u001b[1;32m    341\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloader \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mneighbor\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m--> 342\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mNeighborLoader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_nodes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_nodes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    343\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mneighbor_sampler\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mneighbor_sampler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    344\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshuffle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/mmpyg/lib/python3.10/site-packages/pytorch_lightning/utilities/data.py:516\u001b[0m, in \u001b[0;36m_wrap_init_method.<locals>.wrapper\u001b[0;34m(obj, *args, **kwargs)\u001b[0m\n\u001b[1;32m    513\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m store_explicit_arg \u001b[38;5;129;01min\u001b[39;00m kwargs:\n\u001b[1;32m    514\u001b[0m         \u001b[38;5;28mobject\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__setattr__\u001b[39m(obj, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstore_explicit_arg\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, kwargs[store_explicit_arg])\n\u001b[0;32m--> 516\u001b[0m \u001b[43minit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    517\u001b[0m \u001b[38;5;28mobject\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__setattr__\u001b[39m(obj, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__pl_inside_init\u001b[39m\u001b[38;5;124m\"\u001b[39m, old_inside_init)\n",
      "File \u001b[0;32m~/miniconda3/envs/mmpyg/lib/python3.10/site-packages/torch_geometric/loader/neighbor_loader.py:400\u001b[0m, in \u001b[0;36mNeighborLoader.__init__\u001b[0;34m(self, data, num_neighbors, input_nodes, replace, directed, time_attr, transform, is_sorted, filter_per_worker, neighbor_sampler, **kwargs)\u001b[0m\n\u001b[1;32m    388\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m neighbor_sampler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    389\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mneighbor_sampler \u001b[38;5;241m=\u001b[39m NeighborSampler(\n\u001b[1;32m    390\u001b[0m         data,\n\u001b[1;32m    391\u001b[0m         num_neighbors,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    397\u001b[0m         share_memory\u001b[38;5;241m=\u001b[39mkwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnum_workers\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m0\u001b[39m) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m    398\u001b[0m     )\n\u001b[0;32m--> 400\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43minput_nodes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollate_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/mmpyg/lib/python3.10/site-packages/pytorch_lightning/utilities/data.py:516\u001b[0m, in \u001b[0;36m_wrap_init_method.<locals>.wrapper\u001b[0;34m(obj, *args, **kwargs)\u001b[0m\n\u001b[1;32m    513\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m store_explicit_arg \u001b[38;5;129;01min\u001b[39;00m kwargs:\n\u001b[1;32m    514\u001b[0m         \u001b[38;5;28mobject\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__setattr__\u001b[39m(obj, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstore_explicit_arg\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, kwargs[store_explicit_arg])\n\u001b[0;32m--> 516\u001b[0m \u001b[43minit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    517\u001b[0m \u001b[38;5;28mobject\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__setattr__\u001b[39m(obj, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__pl_inside_init\u001b[39m\u001b[38;5;124m\"\u001b[39m, old_inside_init)\n",
      "File \u001b[0;32m~/miniconda3/envs/mmpyg/lib/python3.10/site-packages/torch/utils/data/dataloader.py:353\u001b[0m, in \u001b[0;36mDataLoader.__init__\u001b[0;34m(self, dataset, batch_size, shuffle, sampler, batch_sampler, num_workers, collate_fn, pin_memory, drop_last, timeout, worker_init_fn, multiprocessing_context, generator, prefetch_factor, persistent_workers, pin_memory_device)\u001b[0m\n\u001b[1;32m    351\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# map-style\u001b[39;00m\n\u001b[1;32m    352\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m shuffle:\n\u001b[0;32m--> 353\u001b[0m         sampler \u001b[38;5;241m=\u001b[39m \u001b[43mRandomSampler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgenerator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgenerator\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m    354\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    355\u001b[0m         sampler \u001b[38;5;241m=\u001b[39m SequentialSampler(dataset)  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/mmpyg/lib/python3.10/site-packages/torch/utils/data/sampler.py:107\u001b[0m, in \u001b[0;36mRandomSampler.__init__\u001b[0;34m(self, data_source, replacement, num_samples, generator)\u001b[0m\n\u001b[1;32m    103\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreplacement should be a boolean value, but got \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    104\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreplacement=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreplacement))\n\u001b[1;32m    106\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_samples, \u001b[38;5;28mint\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_samples \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 107\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_samples should be a positive integer \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    108\u001b[0m                      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue, but got num_samples=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_samples))\n",
      "\u001b[0;31mValueError\u001b[0m: num_samples should be a positive integer value, but got num_samples=0"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    if not in_ipython():\n",
    "        root_dir = os.path.dirname(os.path.realpath(__file__))\n",
    "        parser = ArgumentParser(add_help=False)\n",
    "        hyperparams = parser.parse_args()\n",
    "\n",
    "        # TRAIN\n",
    "        main(hyperparams)\n",
    "    else:\n",
    "        main(None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
