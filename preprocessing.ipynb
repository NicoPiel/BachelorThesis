{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import time\n",
    "import threading\n",
    "import subprocess\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from rdkit import Chem\n",
    "from openbabel import pybel\n",
    "from pqdm.processes import pqdm\n",
    "\n",
    "if not os.path.exists('./temp'):\n",
    "    os.mkdir('./temp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "files = [\n",
    "    'edrug3d.sdf',\n",
    "    'qm9-1.sdf',\n",
    "    'qm9-2.sdf',\n",
    "    'qm9-3.sdf',\n",
    "    'qm9-4.sdf',\n",
    "    'qm9-5.sdf',\n",
    "    'qm9-6.sdf',\n",
    "    'qm9-7.sdf',\n",
    "    'qm9-8.sdf'\n",
    "]\n",
    "\n",
    "\n",
    "def check_missing_files():\n",
    "    \"\"\"Checks for missing files. Returns true, if all files are present.\"\"\"\n",
    "    for file in files:\n",
    "        if not os.path.exists('./data/' + file):\n",
    "            return False\n",
    "\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Download data\n",
    "\n",
    "if not check_missing_files():\n",
    "    !wget -nc -O data.zip \"https://hochschulebonnrheinsieg-my.sharepoint.com/:u:/g/personal/nico_piel_365h-brs_de1/ESuGOTn_IflEk7I5HkOFpbwBZKeOk9Qf2nL5JEcq2om6_Q?e=sHYsTk&download=1\"\n",
    "    !unzip -u data.zip\n",
    "    !rm data.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def ac_to_series(filename: str) -> pd.DataFrame:\n",
    "    df_out = None\n",
    "\n",
    "    with open(filename) as file:\n",
    "        lines = file.readlines()\n",
    "\n",
    "        for line in [a for a in lines if 'ATOM' in a]:\n",
    "            try:\n",
    "                out = {}\n",
    "\n",
    "                a_split = re.compile(r'\\s+').split(line.strip())\n",
    "                atom_name = a_split[2]\n",
    "                atom_type = a_split[9]\n",
    "                out['name'] = atom_name\n",
    "                out['type'] = atom_type\n",
    "\n",
    "                bonds = {\n",
    "                    'C': 0,\n",
    "                    'H': 0,\n",
    "                    'N': 0,\n",
    "                    'O': 0,\n",
    "                    'S': 0,\n",
    "                    'F': 0,\n",
    "                    'Cl': 0,\n",
    "                    'Br': 0,\n",
    "                    'I': 0,\n",
    "                    'Other': 0\n",
    "                }\n",
    "\n",
    "                for bond in [b for b in lines if 'BOND' in b]:\n",
    "                    b_split = re.compile(r'\\s+').split(bond.strip())\n",
    "\n",
    "                    if b_split[5] == atom_name:\n",
    "                        bond_type = re.compile('\\d+').split(b_split[6])[0]\n",
    "\n",
    "                        if bond_type in bonds.keys():\n",
    "                            bonds[bond_type] += 1\n",
    "                        else:\n",
    "                            bonds['Other'] += 1\n",
    "\n",
    "                    elif b_split[6] == atom_name:\n",
    "                        bond_type = re.compile('\\d+').split(b_split[5])[0]\n",
    "\n",
    "                        if bond_type in bonds.keys():\n",
    "                            bonds[bond_type] += 1\n",
    "                        else:\n",
    "                            bonds['Other'] += 1\n",
    "\n",
    "                out.update(bonds)\n",
    "                bond_df = pd.DataFrame(out, index=[0])\n",
    "\n",
    "                if df_out is None:\n",
    "                    df_out = pd.DataFrame(columns=bond_df.columns)\n",
    "\n",
    "                df_out = pd.concat([df_out, bond_df], ignore_index=True)\n",
    "            except IndexError:\n",
    "                print(f'Index out of range in {filename}, line: {a}')\n",
    "                print(f'a_split only has {len(a_split)} elements.')\n",
    "\n",
    "    return df_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def sdf_to_list(filename: str) -> list:\n",
    "    \"\"\"Converts an sdf file to a Python list.\"\"\"\n",
    "    with open(filename, \"rt\") as file:\n",
    "        return file.read().split(r'$$$$')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_list = []\n",
    "\n",
    "\n",
    "def sdf_to_df(file_name: str) -> pd.DataFrame:\n",
    "    mols = sdf_to_list('./data/' + file_name)\n",
    "    df = None\n",
    "    file_name_split = file_name.split('.')[0]\n",
    "\n",
    "    if not os.path.exists('./temp/' + file_name_split):\n",
    "        os.mkdir('./temp/' + file_name_split)\n",
    "\n",
    "    new_path = './temp/' + file_name_split + '/'\n",
    "\n",
    "    for mol in mols:\n",
    "        # Strip leading new lines\n",
    "        mol = mol.lstrip()\n",
    "\n",
    "        # Split on new lines to correct for mistakes made by splitting the sdf molecules\n",
    "        split = mol.split('\\n')\n",
    "        curr_split_len = len(split)\n",
    "\n",
    "        if curr_split_len > 5:\n",
    "            # Insert a new line if line 4 isn't in the correct place\n",
    "            if re.compile(r'\\s*\\d+\\s*\\d+\\s*\\d+\\s*\\d+\\s*').match(split[3]) is None:\n",
    "                mol = '\\n' + mol\n",
    "\n",
    "            # Write molecule to a file so antechamber can read it\n",
    "            with open(new_path + 'mol.sdf', 'w') as file:\n",
    "                file.write(mol)\n",
    "\n",
    "            # Run antechamber and divert output to a file (temporary)\n",
    "            subprocess.getoutput(\n",
    "                f\"cd {new_path} && antechamber -i mol.sdf -fi mdl -o mol.ac -fo ac -at gaff2 -pf y\"\n",
    "            )\n",
    "\n",
    "            # Convert ac atom types to a new dataframe\n",
    "            ac_df = ac_to_series(new_path + 'mol.ac')\n",
    "\n",
    "            if df is None:\n",
    "                df = pd.DataFrame(columns=ac_df.columns)\n",
    "\n",
    "            # Attach new row to existing dataframe\n",
    "            df = pd.concat([df, ac_df], ignore_index=True)\n",
    "        else:\n",
    "            print('end')\n",
    "\n",
    "    # Clean up remaining files\n",
    "    try:\n",
    "        os.remove(new_path + 'mol.ac')\n",
    "        os.remove(new_path + 'mol.sdf')\n",
    "    except IOError:\n",
    "        print('Something went wrong.')\n",
    "\n",
    "    # Attach completed dataframe to the output frame.\n",
    "    df_list.append(df)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class PreprocessingThread(threading.Thread):\n",
    "    def __init__(self, file_name):\n",
    "        threading.Thread.__init__(self)\n",
    "        self.file_name = file_name\n",
    "\n",
    "    def run(self):\n",
    "        print(\"Starting \" + self.file_name)\n",
    "        sdf_to_df(self.file_name)\n",
    "        print(\"Exiting \" + self.file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "threads = []  # list of threads so they can be manipulated later\n",
    "\n",
    "pqdm(files, sdf_to_df, n_jobs=len(files))\n",
    "\n",
    "# Create a thread for each file\n",
    "# for file in files:\n",
    "#    thread = PreprocessingThread(file)\n",
    "#    threads.append(thread)\n",
    "# Start threads\n",
    "# for thread in threads:\n",
    "#    thread.start()\n",
    "# Wait for them to finish\n",
    "# for thread in threads:\n",
    "#    thread.join()\n",
    "\n",
    "# Concatenate dfs in the list\n",
    "mol_df = pd.concat(df_list, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "mol_df.to_csv('./data/data.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "07bca49d2aa91ba30708eb691bb51c14e8f9a0701c6e92c94ace8ce2abd85168"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
