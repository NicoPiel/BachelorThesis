{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "840f1a55-6e23-4e19-b78e-732c782ef318",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_922/1394593694.py:44: DeprecationWarning: `set_matplotlib_formats` is deprecated since IPython 7.23, directly use `matplotlib_inline.backend_inline.set_matplotlib_formats()`\n",
      "  set_matplotlib_formats(\"svg\", \"pdf\")  # For export\n",
      "Global seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA: True\n",
      "Device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "\n",
    "import os\n",
    "import re\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "\n",
    "# PyTorch Lightning\n",
    "import pytorch_lightning as pl\n",
    "import seaborn as sns\n",
    "\n",
    "# PyTorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from IPython.display import set_matplotlib_formats\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "\n",
    "# Import GPU-related things\n",
    "if torch.cuda.is_available():\n",
    "    # import cupy as np\n",
    "    # import cudf as pd\n",
    "\n",
    "    # Ensure that all operations are deterministic on GPU (if used) for reproducibility\n",
    "    torch.backends.cudnn.determinstic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "# else:\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "device = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "\n",
    "# Plotting\n",
    "plt.set_cmap(\"cividis\")\n",
    "%matplotlib inline\n",
    "set_matplotlib_formats(\"svg\", \"pdf\")  # For export\n",
    "matplotlib.rcParams[\"lines.linewidth\"] = 2.0\n",
    "sns.reset_orig()\n",
    "\n",
    "# Path to the folder where the datasets are/should be downloaded (e.g. CIFAR10)\n",
    "DATASET_PATH = os.environ.get(\"PATH_DATASETS\", \"data/\")\n",
    "# Path to the folder where the pretrained models are saved\n",
    "CHECKPOINT_PATH = os.environ.get(\"PATH_CHECKPOINT\", \"saved_models/\")\n",
    "\n",
    "# Setting the seed\n",
    "pl.seed_everything(42)\n",
    "\n",
    "print('CUDA:', torch.cuda.is_available())\n",
    "print(\"Device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "10861759-61e4-441a-8bda-2124cc474a18",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "files = [\n",
    "    'data.csv',\n",
    "    'edrug3d.sdf',\n",
    "    'qm9-1.sdf',\n",
    "    'qm9-2.sdf',\n",
    "    'qm9-3.sdf',\n",
    "    'qm9-4.sdf',\n",
    "    'qm9-5.sdf',\n",
    "    'qm9-6.sdf',\n",
    "    'qm9-7.sdf',\n",
    "    'qm9-8.sdf'\n",
    "]\n",
    "\n",
    "\n",
    "def check_missing_files():\n",
    "    \"\"\"Checks for missing files. Returns true, if all files are present.\"\"\"\n",
    "    for file in files:\n",
    "        if not os.path.exists('./data/' + file):\n",
    "            return False\n",
    "\n",
    "    return True\n",
    "\n",
    "\n",
    "if not check_missing_files():\n",
    "    !wget -nc -O data.zip \"https://hochschulebonnrheinsieg-my.sharepoint.com/:u:/g/personal/nico_piel_365h-brs_de1/ESuGOTn_IflEk7I5HkOFpbwBZKeOk9Qf2nL5JEcq2om6_Q?e=sHYsTk&download=1\"\n",
    "    !unzip -u data.zip\n",
    "    !rm data.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "11a632cd-df69-435b-8323-73165083753d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class CustomDataset(data.Dataset):\n",
    "    def __init__(self, path):\n",
    "        super().__init__()\n",
    "        self.data = pd.read_csv(path)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.data.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        series = self.data.iloc[idx]\n",
    "        return series[0], series[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1e711ee0-04e9-40a5-83a0-3a0b8fdd3a17",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dataset = CustomDataset('./data/data.csv')\n",
    "dataloader = data.DataLoader(dataset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f0d98761-8a2b-4ca5-bf90-fd5b72af0075",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get maximum sentence length\n",
    "def get_max_sentence_length() -> np.ndarray:\n",
    "    return np.array([len(features[0]) for features in dataset])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e91994eb-5ce2-4c25-8bfd-7f74834178f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = np.max(get_max_sentence_length())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "bca6ad0a-08d3-4a36-a70e-fa5e2ef31c61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S(=O)(=O)(Nc1ncccc1)c1ccc(N)cc1\n",
      "['S', '(', '=', 'O', ')', '(', '=', 'O', ')', '(', 'N', 'c', '1', 'n', 'c', 'c', 'c', 'c', '1', ')', 'c', '1', 'c', 'c', 'c', '(', 'N', ')', 'c', 'c', '1']\n",
      "sy|o|o|nu|nb|nv|ca|ca|ca|ca|ca|ca|ca|ca|ca|ca|ca|hn|ha|ha|ha|ha|ha|ha|hn|hn|ha|h4\n",
      "['sy', 'o', 'o', 'nu', 'nb', 'nv', 'ca', 'ca', 'ca', 'ca', 'ca', 'ca', 'ca', 'ca', 'ca', 'ca', 'ca', 'hn', 'ha', 'ha', 'ha', 'ha', 'ha', 'ha', 'hn', 'hn', 'ha', 'h4']\n"
     ]
    }
   ],
   "source": [
    "# SMILES regex by Schwaller et. al.\n",
    "smiles_regex = r\"\"\"(\\[[^\\]]+]|Br?|Cl?|N|O|S|P|F|I|b|c|n|o|s|p|\\(|\\)|\\.|=|#|-|\\+|\\\\|\\/|:|~|@|\\?|>>?|\\*|\\$|\\%[0-9]{2}|[0-9])\"\"\"\n",
    "at_regex = r\"\\w+|\\w+\"\n",
    "\n",
    "smiles_tokenizer = RegexpTokenizer(smiles_regex)\n",
    "at_tokenizer = RegexpTokenizer(at_regex)\n",
    "\n",
    "print(dataset[0][0])\n",
    "print(smiles_tokenizer.tokenize(dataset[0][0]))\n",
    "\n",
    "print(dataset[0][1])\n",
    "print(at_tokenizer.tokenize(dataset[0][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "624e7fd0-8d9c-4871-a0e6-e60f9408d6bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build vocabs\n",
    "smiles_vocab = build_vocab_from_iterator([smiles_tokenizer.tokenize(feature[0]) for feature in dataset])\n",
    "at_vocab = build_vocab_from_iterator([at_tokenizer.tokenize(feature[1]) for feature in dataset])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "f7d073d5-56d0-4391-b9ce-6f4e00461e7d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class ATTransformer(pl.LightningModule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.train_dataset = CustomDataset('.data/data.csv')\n",
    "        self.save_hyperparameters()\n",
    "        self._create_model()\n",
    "\n",
    "    def _create_model(self):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def forward(self, X):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return data.DataLoader(self.train_dataset, batch_size=64, shuffle=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
